#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage{pgfplots}
\usepackage{enumitem}
\setenumerate{label=A)}
\setenumerate[2]{label=a)}
\end_preamble
\use_default_options true
\begin_modules
theorems-ams
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Subsection
Teorema de De Finetti
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
https://people.eecs.berkeley.edu/~jordan/courses/260-spring10/lectures/lecture1.pdf
\end_layout

\begin_layout Plain Layout
http://wwwf.imperial.ac.uk/~das01/MyWeb/M3S3/Handouts/DeFinetti.pdf
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Las urnas de Polya son un buen ejemplo de variables aleatorias intercambiables
\end_layout

\begin_layout Section
Primeros ejemplos de medida de De Finetti
\end_layout

\begin_layout Standard
A pesar de que el teorema de representación de De Finetti nos garantizan
 la existencia de una distribución a priori no nos dice cual es el precisamente,
 podemos recolectar algunos ejemplos de ciertas bibliografías para hacernos
 una idea de como operar con estos conceptos.
 Si tenemos una muestra aleatoria independiente es simple ver que
\begin_inset Formula 
\[
f\left(x_{1},\ldots,x_{n}\right)=\prod_{i=1}^{n}f\left(x_{i}\right)\implies f\left(x_{n+1},\ldots,x_{n+m}|x_{1},\ldots,x_{n}\right)=\prod_{i=n+1}^{m}f\left(x_{i}\right)
\]

\end_inset

, esto quiere decir que no hay aprendizaje desde la experiencia.
 
\begin_inset Marginal
status open

\begin_layout Plain Layout
no hay aprendizaje desde la experiencia
\end_layout

\end_inset

 
\end_layout

\begin_layout Theorem
Sea 
\begin_inset Formula $\theta\sim f\left(\theta\right)$
\end_inset

 y 
\begin_inset Formula $Y_{1},\ldots,Y_{n}$
\end_inset

 condicionalmente independientes de 
\begin_inset Formula $\theta$
\end_inset

 entonces 
\begin_inset Formula $Y_{1},\ldots,Y_{n}$
\end_inset

 es intercambiable.
\end_layout

\begin_layout Proof
Basta con probar lo siguiente 
\begin_inset Formula 
\begin{align*}
f\left(y_{1},\ldots,y_{n}\right) & =\int f\left(y_{1},\ldots,y_{n}|\theta\right)dF\left(\theta\right)\\
 & =\int\prod_{i=1}^{n}f\left(y_{i}|\theta\right)dF\left(\theta\right)\\
 & =f\left(y_{\pi_{1}},\ldots,y_{\pi_{n}}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Básicamente el teorema de De Finetti es el recíproco de esta proposición.
 La prueba de De Finetti para variables aleatorias dicotómicas se explica
 a continuación.
 Consideremos el caso de una secuencia intercambiable de variables aleatorias
 
\begin_inset Formula $0-1$
\end_inset

.
 Entonces 
\begin_inset Formula 
\begin{align*}
p\left(y_{1},\ldots,y_{n}\right) & =\int\prod_{i=1}^{n}p\left(y_{i}|\theta\right)dF\left(\theta\right)
\end{align*}

\end_inset

donde 
\begin_inset Formula 
\[
F\left(\theta\right)=\lim_{n\to\infty}P\left(s_{n}\leq\theta\right)
\]

\end_inset

notemos que 
\begin_inset Formula 
\[
p\left(y_{1}+\ldots+y_{n}=s_{n}\right)=\binom{n}{s_{n}}p\left(y_{1},\ldots,y_{n}\right)=\binom{n}{s_{n}}p\left(y_{\pi_{1}},\ldots,y_{\pi_{n}}\right)
\]

\end_inset

dado que vale para cualquier permutación, ahora bien, sea 
\begin_inset Formula $N>n$
\end_inset

 entonces 
\begin_inset Formula 
\[
p\left(y_{1}+\ldots+y_{n}=s_{n}\right)=\sum p\left(y_{1}+\ldots+y_{n}=s_{n}|y_{1}+\ldots+y_{N}=s_{N}\right)p\left(y_{1}+\ldots+y_{N}=s_{N}\right)
\]

\end_inset


\end_layout

\begin_layout Subsection
Urnas de Polya 
\end_layout

\begin_layout Standard
Las urnas de Polya son un buen ejemplo de intercambiabilidad: Tenemos 
\begin_inset Formula $b_{0}$
\end_inset

 bolitas negras y 
\begin_inset Formula $w_{0}$
\end_inset

 bolitas blancas en una urna.
 Extraigo una bolita aleatoriamente, si es blanca retorno la bolita a la
 urna y agrego una blanca, si es negra retorno la bolita y agrego una negra.
 
\begin_inset Formula $B_{n}:$
\end_inset

 El número de bolas negras dado 
\begin_inset Formula $n$
\end_inset

 ensayos es.
\begin_inset Formula 
\[
B_{n}\sim Bin\left(n,\frac{b_{0}}{b_{0}+w_{0}}\right)
\]

\end_inset

la demostración biene como sigue 
\begin_inset Formula 
\begin{align*}
\text{Bolas negras iniciales }B_{0} & =b_{0}\\
\implies P\left(B_{0}=b_{0}\right) & =1\\
P\left(B_{1}=b_{0}+1\right) & =\frac{b_{0}}{b_{0}+w_{0}}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Para 
\begin_inset Formula $n=2$
\end_inset

 
\begin_inset Formula 
\begin{align*}
P\left(B_{2}=b_{0}\right) & =\frac{w_{0}}{w_{0}+b_{0}}\cdot\frac{w_{0}+1}{w_{0}+b_{0}+1}\\
P\left(B_{2}=b_{0}+1\right) & =\frac{w_{0}}{w_{0}+b_{0}}\frac{b_{0}}{w_{0}+b_{0}+1}+\frac{b_{0}}{w_{0}+b_{0}}\frac{w_{0}}{w_{0}+b_{0}+1}\\
P\left(B_{2}=b_{0}+2\right) & =\frac{b_{0}}{w_{0}+b_{0}}\cdot\frac{b_{0}+1}{w_{0}+b_{0}+1}
\end{align*}

\end_inset

debemos demostrar que la secuencia de variables aleatorias 
\begin_inset Formula $X_{1},\ldots,X_{n}$
\end_inset

 de la secuencua de colores en cada una de las 
\begin_inset Formula $n$
\end_inset

 extracciones en la urna es una secuencia de variables aleatorias intercambiable
s.
 Sea 
\begin_inset Formula $Y_{n}$
\end_inset

 la proporción de bolas negras en la urna en dado 
\begin_inset Formula $n$
\end_inset

 ensayos.
 
\begin_inset Formula 
\[
Y_{n}=\frac{B_{n}}{B_{n}+W_{n}}=\frac{B_{n}}{b_{0}+w_{0}+n}
\]

\end_inset

con esto podemos decir que 
\begin_inset Formula 
\[
B_{n+1}=\begin{cases}
B_{n} & \text{con probabilidad }1-Y_{n}\\
B_{n}+1 & \text{con probabilidad }Y_{n}
\end{cases}
\]

\end_inset

entonces 
\begin_inset Formula 
\begin{align*}
E\left(Y_{n+1}|X_{1},\ldots,X_{n}\right) & =E\left(\frac{B_{n+1}}{b_{0}+w_{0}+n}|X_{1},\ldots,X_{n}\right)\\
 & =\frac{1}{b_{0}+w_{0}+n}E\left(B_{n+1}|X_{1},\ldots,X_{n}\right)\\
 & =\frac{1}{b_{0}+w_{0}+n}\left(B_{n}\left(1-Y_{n}\right)+\left(B_{n}+1\right)Y_{n}\right)\\
 & =\frac{1}{b_{0}+w_{0}+n}\left(B_{n}-B_{n}Y_{n}+B_{n}Y_{n}+Y_{n}\right)\\
 & =\frac{1}{b_{0}+w_{0}+n}\left(B_{n}+Y_{n}\right)\\
 & =Y_{n}
\end{align*}

\end_inset


\end_layout

\begin_layout Subsection
Blackwell and MacQueen 1973
\end_layout

\begin_layout Standard
Revisaremos la implicancias de este artículo en estadística bayesiana no
 paramétrica.
\end_layout

\begin_layout Section
BDA 3
\end_layout

\begin_layout Standard
En esta sección se ilustrarán algunos conceptos útiles expuestos en el libro
 de Gelman y algunos ejercicios que son frecuentes en cátedras de inferencia
 bayesiana que se basan en el texto.
\end_layout

\begin_layout Subsection
Introducció y motivación
\end_layout

\begin_layout Subsection
Modelos uniparamétricos
\end_layout

\begin_layout Problem
\begin_inset Argument 1
status open

\begin_layout Plain Layout
cap2.prob5
\end_layout

\end_inset

La distribución a posterior es un compromiso entre la priori y los datos:
 Sea 
\begin_inset Formula $n$
\end_inset

 el número de lanzamientos de una moneda, la cual tiene probabilidad de
 
\begin_inset Formula $\theta$
\end_inset

 de ser cara.
 (a) Si la distribución a priori es una uniforme entre 
\begin_inset Formula $0,1$
\end_inset

, derive la distribución predictiva 
\begin_inset Formula 
\[
p\left(y=k\right)=\int_{0}^{1}p\left(y=k|\theta\right)d\theta
\]

\end_inset

para cada 
\begin_inset Formula $k=1,\ldots,n$
\end_inset

.
 Sol: 
\begin_inset Formula 
\begin{align*}
p\left(y=k\right) & =\int_{0}^{1}p\left(y=k,\theta\right)d\theta\\
 & =\int_{0}^{1}p\left(y=k|\theta\right)\underbrace{p\left(\theta\right)}_{1}d\theta\\
 & =\int_{0}^{1}p\left(y=k|\theta\right)d\theta\\
 & =\int_{0}^{1}\binom{n}{k}\theta^{k}\left(1-\theta\right)^{n-k}d\theta\\
 & =\binom{n}{k}\int_{0}^{1}\theta^{k}\left(1-\theta\right)^{n-k}d\theta\\
 & =\binom{n}{k}\frac{\Gamma\left(k+1\right)\Gamma\left(n-k+1\right)}{\Gamma\left(n+2\right)}\\
 & =\binom{n}{k}\frac{k!\left(n-k\right)!}{\left(n+1\right)!}\\
 & =\frac{1}{n+1}
\end{align*}

\end_inset

usamos el siguiente resultado 
\begin_inset Formula 
\begin{align*}
\int_{0}^{1}\frac{\Gamma\left(\alpha+\beta\right)}{\Gamma\left(\alpha\right)\Gamma\left(\beta\right)}\theta^{\alpha-1}\left(1-\theta\right)^{\beta-1}d\theta & =1\\
\implies\int_{0}^{1}\theta^{\alpha-1}\left(1-\theta\right)^{\beta-1}d\theta & =\frac{\Gamma\left(\alpha\right)\Gamma\left(\beta\right)}{\Gamma\left(\alpha+\beta\right)}\\
\implies\int_{0}^{1}\theta^{k}\left(1-\theta\right)^{n-k}d\theta & =\frac{\Gamma\left(k+1\right)\Gamma\left(n-k+1\right)}{\Gamma\left(k+1+n-k+1\right)}=\frac{\Gamma\left(k+1\right)\Gamma\left(n-k+1\right)}{\Gamma\left(n+2\right)}
\end{align*}

\end_inset

(b) Supona que asigna una distribución 
\begin_inset Formula $\theta\sim\text{beta}\left(\alpha,\beta\right)$
\end_inset

 y usted observa 
\begin_inset Formula $y$
\end_inset

 caras en sus 
\begin_inset Formula $n$
\end_inset

 lanzamientos.
 Muestre algebraicamente que la media posterior involucra a la media a priori
 y la media de los datos.
 
\begin_inset Formula 
\begin{align*}
p\left(\theta|y\right) & \propto p\left(y|\theta\right)p\left(\theta\right)\\
 & =\binom{n}{y}\theta^{y}\left(1-\theta\right)^{n-y}\frac{\Gamma\left(\alpha+\beta\right)}{\Gamma\left(\alpha\right)\Gamma\left(\beta\right)}\theta^{\alpha-1}\left(1-\theta\right)^{\beta-1}\\
 & \propto\theta^{\alpha+y-1}\left(1-\theta\right)^{\beta+n-y-1}\\
\implies\theta|y & \sim\text{beta}\left(\alpha+y,\beta+n-y\right)
\end{align*}

\end_inset

luego, la media condicional 
\begin_inset Formula 
\begin{align*}
E\left(\theta|y\right) & =\frac{\alpha+y}{\alpha+y+\beta+n-y}\\
 & =\frac{\alpha+y}{\alpha+\beta+n}\\
 & =\frac{\alpha}{\alpha+\beta+n}+\frac{y}{\alpha+\beta+n}\\
 & =\frac{\alpha+\beta}{\alpha+\beta}\frac{\alpha}{\alpha+\beta+n}+\frac{n}{n}\frac{y}{\alpha+\beta+n}\\
 & =\frac{\alpha+\beta}{\alpha+\beta+n}\underbrace{\frac{\alpha}{\alpha+\beta}}_{E\left(\theta\right)}+\frac{n}{\alpha+\beta+n}\frac{y}{n}
\end{align*}

\end_inset


\end_layout

\begin_layout Paragraph*
2.5c.
 
\end_layout

\begin_layout Standard
Muestre que si la priori es uniforme entonces la media a posteriori, entonces
 la varianza a posterior es siempre menor a la varianza a priori.
 Sol: Sea 
\begin_inset Formula $\theta\sim\text{beta}\left(1,1\right)$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\text{Var}\left(\theta|y\right) & =\frac{\left(\alpha+y\right)\left(\beta+n-y\right)}{\left(\alpha+y+\beta+n-y\right)^{2}\left(\alpha+y+\beta+n-y\right)}\\
 & =\frac{\left(\alpha+y\right)\left(\beta+n-y\right)}{\left(\alpha+\beta+n\right)^{2}\left(\alpha+\beta+n+1\right)}\\
 & =\frac{\left(1+y\right)\left(1+n-y\right)}{\left(2+n\right)^{2}\left(2+n+1\right)}=\frac{\left(1+y\right)\left(1+n-y\right)}{\left(2+n\right)^{2}\left(n+3\right)}\leq\frac{1}{12}=\text{Var}\left(\theta\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Paragraph*
2.5d.
 
\end_layout

\begin_layout Standard
De un ejemplo de una priori 
\begin_inset Formula $\text{beta}\left(\alpha,\beta\right)$
\end_inset

 con 
\begin_inset Formula $y$
\end_inset

 y 
\begin_inset Formula $n$
\end_inset

 donde va varianza posterior es menor a la varianza a priori.
 Sol.
 
\begin_inset Formula 
\[
\frac{\left(\alpha+y\right)\left(\beta+n-y\right)}{\left(\alpha+\beta+n\right)^{2}\left(\alpha+\beta+n+1\right)}\leq\frac{\alpha\beta}{\left(\alpha+\beta\right)^{2}\left(\alpha+\beta+1\right)}
\]

\end_inset

y seleccionamos valores que respeten la igualdad.
\end_layout

\begin_layout Paragraph*
2.7a.
\end_layout

\begin_layout Standard
Sobre prioris no informativas: Para la verosimilitud binomial 
\begin_inset Formula $y\sim\text{bin}\left(n,\theta\right)$
\end_inset

 , muestre que 
\begin_inset Formula $p\left(\theta\right)\propto\theta^{-1}\left(1-\theta\right)^{-1}$
\end_inset

 es la priori uniforme para el parámetro natural de la familia exponencial.
 Sol.
 Sabemos que la función de enlace canónica de distribución binomial es 
\begin_inset Formula $\phi=\log\left(\frac{\theta}{1-\theta}\right)=h\left(\theta\right)$
\end_inset

.
 sabiendo que 
\begin_inset Formula 
\begin{align*}
p\left(\theta\right) & =\underbrace{p\left(\phi\right)}_{\propto1}\left|\frac{d\phi}{d\theta}\right|\\
 & \propto\left|\frac{d}{d\theta}\log\left(\frac{\theta}{1-\theta}\right)\right|\\
 & =\frac{1}{\theta}+\frac{1}{1-\theta}\\
 & =\theta^{-1}\left(1-\theta\right)^{-1}
\end{align*}

\end_inset

 .ver BDA (ecuación 2.19) 
\end_layout

\begin_layout Paragraph*
2.7b.
\end_layout

\begin_layout Standard
Muestre que si 
\begin_inset Formula $y=0$
\end_inset

 o 
\begin_inset Formula $n=0$
\end_inset

 la distribución posterior es impropia.
 Sol: Si tenemos que 
\begin_inset Formula 
\begin{align*}
p\left(\theta|y\right) & \propto p\left(y|\theta\right)p\left(\theta\right)\\
 & =\binom{n}{y}\theta^{y}\left(1-\theta\right)^{n-y}\theta^{-1}\left(1-\theta\right)^{-1}\\
 & \propto\theta^{y-1}\left(1-\theta\right)^{n-y-1}=\begin{cases}
\theta^{-1}\left(1-\theta\right)^{n-1} & y=0\\
\theta^{-1}\left(1-\theta\right)^{-1} & n=0\\
\theta^{y-1}\left(1-\theta\right)^{n-y-1} & \text{otro caso}
\end{cases}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
en los dos primeros casos no integra 1
\end_layout

\begin_layout Paragraph*
2.8a.
 
\end_layout

\begin_layout Standard
Distribución normal con media desconocida: Sea una muestra aleatoria de
 
\begin_inset Formula $n$
\end_inset

 estudiantes extraidos de una población lo suficientemente grande para luego
 medir su peso.
 La media del peso viene dada por 
\begin_inset Formula $\overline{y}=150$
\end_inset

.
 Asuma que pero en la población se distribuye normal con media desconocida
 
\begin_inset Formula $\theta$
\end_inset

 y desviación estandar de 
\begin_inset Formula $20$
\end_inset

.
 Suponga una distribución a priori para 
\begin_inset Formula $\theta$
\end_inset

 normal con media 
\begin_inset Formula $180$
\end_inset

 y desviación estandar de 
\begin_inset Formula $40$
\end_inset

.
 Encuentre la distribución a posterior de 
\begin_inset Formula $\theta$
\end_inset

.
 Sol: Solo con el objetivo de ejercitar todos los pasos deduciremos la distribuc
ión a posterior completamente.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
y|\theta & \sim N\left(\theta,\sigma^{2}\right)\\
\theta & \sim N\left(\mu_{0},\tau_{0}^{2}\right)
\end{align*}

\end_inset

entonces tenemos que 
\begin_inset Formula 
\begin{align*}
p\left(\theta|y\right) & \propto p\left(y|\theta\right)p\left(\theta\right)\\
 & =\prod_{i=1}^{n}\left[\left(2\pi\sigma^{2}\right)^{-1/2}\exp\left(-\frac{1}{2\sigma^{2}}\left(y_{i}-\theta\right)^{2}\right)\right]\left(2\pi\tau_{0}^{2}\right)^{-1/2}\exp\left(-\frac{1}{2\tau_{0}^{2}}\left(\theta-\mu_{0}\right)^{2}\right)\\
 & \propto\exp\left(\frac{1}{2\sigma^{2}}\sum_{i=1}^{n}\left(y_{i}-\theta\right)^{2}\right)\exp\left(\frac{1}{2\tau_{0}^{2}}\left(\theta-\mu_{0}\right)^{2}\right)\\
 & =\exp\left(-\frac{1}{2\sigma^{2}}\sum_{i=1}^{n}\left(y_{i}-\theta\right)^{2}-\frac{1}{2\tau_{0}^{2}}\left(\theta-\mu_{0}\right)^{2}\right)\\
 & \propto\exp\left(-\frac{1}{2\sigma^{2}}\sum_{i=1}^{n}\left(y_{i}^{2}-2y_{i}\theta+\theta^{2}\right)-\frac{1}{2\tau_{0}^{2}}\left(\theta^{2}-2\theta\mu_{0}+\mu^{2}\right)\right)\\
 & \propto\exp\left(-\frac{1}{2\sigma^{2}}\sum_{i=1}^{n}\left(\theta^{2}-2y_{i}\theta\right)-\frac{1}{2\tau_{0}^{2}}\left(\theta^{2}-2\theta\mu_{0}\right)\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
entonces 
\begin_inset Formula 
\[
\theta|y\sim N\left(\frac{\frac{1}{\sigma^{2}}\mu_{0}+\frac{n}{\tau_{0}^{2}}\overline{y}}{\frac{1}{\sigma^{2}}+\frac{n}{\tau_{0}^{2}}},\frac{1}{\frac{1}{\sigma^{2}}+\frac{n}{\tau_{0}^{2}}}\right)
\]

\end_inset

para nuestro caso tenemos que 
\begin_inset Formula 
\[
\theta|y\sim N\left(\frac{\frac{1}{\sigma^{2}}\mu_{0}+\frac{n}{\tau_{0}^{2}}\overline{y}}{\frac{1}{\sigma^{2}}+\frac{n}{\tau_{0}^{2}}},\frac{1}{\frac{1}{\sigma^{2}}+\frac{n}{\tau_{0}^{2}}}\right)
\]

\end_inset

en nuestro cado 
\begin_inset Formula 
\[
\theta|y\sim N\left(\frac{\frac{1}{20^{2}}180+\frac{n}{40^{2}}150}{\frac{1}{20^{2}}+\frac{n}{40^{2}}},\frac{1}{\frac{1}{20^{2}}+\frac{n}{40^{2}}}\right)
\]

\end_inset


\end_layout

\begin_layout Paragraph*
2.8b.
\end_layout

\begin_layout Standard
La forma de encontrar la distribución predictiva en media esperanza y varianza
 iterada.
 
\begin_inset Formula 
\[
\tilde{y}|y\sim N\left(\widetilde{\mu},\widetilde{\sigma}^{2}\right)
\]

\end_inset

donde 
\begin_inset Formula 
\begin{align*}
\widetilde{\mu} & =E\left(\tilde{y}|y\right)\\
 & =E\left(E\left(\tilde{y}|\theta,y\right)|y\right)\\
 & =E\left(E\left(\tilde{y}|\theta\right)|y\right)\\
 & =E\left(\theta|y\right)\\
 & =\frac{\frac{1}{\sigma^{2}}\mu_{0}+\frac{n}{\tau_{0}^{2}}\overline{y}}{\frac{1}{\sigma^{2}}+\frac{n}{\tau_{0}^{2}}}
\end{align*}

\end_inset

y la varianza 
\begin_inset Formula 
\begin{align*}
\widetilde{\sigma}^{2} & =var\left(\tilde{y}|y\right)\\
 & =var\left(E\left(\tilde{y}|\theta\right)|y\right)+E\left(var\left(\tilde{y}|\theta\right)|y\right)\\
 & =var\left(\theta|y\right)+E\left(\sigma^{2}|y\right)\\
 & =\frac{1}{\frac{1}{\sigma^{2}}+\frac{n}{\tau_{0}^{2}}}+\sigma^{2}
\end{align*}

\end_inset

por lo tanto 
\begin_inset Formula 
\[
\tilde{y}|y\sim N\left(\frac{\frac{1}{20^{2}}180+\frac{n}{40^{2}}150}{\frac{1}{20^{2}}+\frac{n}{40^{2}}},\frac{1}{\frac{1}{\sigma^{2}}+\frac{n}{\tau_{0}^{2}}}+\sigma^{2}\right)
\]

\end_inset


\end_layout

\begin_layout Paragraph*
4.2.a
\end_layout

\begin_layout Standard
normalidad asintótica de la posterior: sea 
\begin_inset Formula $y_{1}\ldots,y_{5}$
\end_inset

 muestras independientes de una distribución cauchy con parametro de posición
 desconocido 
\begin_inset Formula $\theta$
\end_inset

 y escala conicda 
\begin_inset Formula $1$
\end_inset

.
 
\begin_inset Formula $p\left(y_{i}|\theta\right)\propto\frac{1}{1+\left(y_{i}-\theta\right)^{2}}$
\end_inset

.
 Asuma que la distribución a priori para 
\begin_inset Formula 
\[
\theta\sim\text{uniforme}\left(0,1\right)
\]

\end_inset

 determine la derivada y la segunda derivada del logaritmo de la verosimilitud.
 sol
\begin_inset Formula 
\[
l\left(\theta|y\right)=\prod_{i=1}^{n}\frac{1}{1+\left(y_{i}-\theta\right)^{2}}
\]

\end_inset


\end_layout

\begin_layout Section
Ayudantía
\end_layout

\begin_layout Standard
Ejercicios de las ayudantías del segundo semestre del 2020
\end_layout

\begin_layout Subsection
Ayudantía 1
\end_layout

\begin_layout Subsection
Ayudantía 2
\end_layout

\begin_layout Subsection
Ayudantía 3
\end_layout

\begin_layout Subsection
Ayudantía 4
\end_layout

\begin_layout Subsection
Ayudantía 5
\end_layout

\begin_layout Paragraph
4.5.1a.
\end_layout

\begin_layout Standard
\begin_inset Formula $x_{i}$
\end_inset

 permutables 
\begin_inset Formula $p\left(\mu,\sigma^{2}\right)\propto\left(\sigma^{2}\right)^{-3/2}$
\end_inset

.
 Buscamos la distribución a posterior 
\begin_inset Formula 
\begin{align*}
p\left(\mu,\sigma^{2}|\mathbf{x}\right) & \propto p\left(\mu,\sigma^{2}\right)p\left(\mathbf{x}|\mu,\sigma^{2}\right)\\
 & =\left(\sigma^{2}\right)^{-3/2}\sigma^{-n/2}\exp\left(-\frac{1}{2\sigma^{2}}\sum\left(x_{i}-\mu\right)^{2}\right)\\
 & =\left(\sigma^{2}\right)^{-3/2}\sigma^{-n/2}\exp\left(-\frac{1}{2\sigma^{2}}\sum\left(x_{i}-\overline{x}\right)^{2}+n\left(\overline{x}-\mu\right)^{2}\right)\\
 & =\left(\sigma^{2}\right)^{-3/2}\sigma^{-n/2}\exp\left(-\frac{1}{2\sigma^{2}}\left(\sum\left(x_{i}-\overline{x}\right)^{2}+n\left(\overline{x}-\mu\right)^{2}\right)\right)\\
 & =\left(\sigma^{2}\right)^{-3/2-n/2}\exp\left(-\frac{1}{2\sigma^{2}}\left(\left(n-1\right)s^{2}+n\left(\overline{x}-\mu\right)^{2}\right)\right)\\
\text{kerner de una normal} & \propto\exp\left(-\frac{1}{2\sigma^{2}}\left(n\left(\overline{x}-\mu\right)^{2}\right)\right)\\
\implies\mu|\mathbf{x},\sigma^{2} & \sim N\left(\overline{x},\sigma^{2}/n\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Paragraph
4.5.1b.
\end_layout

\begin_layout Standard
posteriori marginal
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
p\left(\mu,\sigma^{2}|\mathbf{x}\right) & \propto\left(\sigma^{2}\right)^{-3/2-n/2}\exp\left(-\frac{1}{2\sigma^{2}}\left(\left(n-1\right)s^{2}+n\left(\overline{x}-\mu\right)^{2}\right)\right)\\
 & =\left(\sigma^{2}\right)^{-3/2-n/2}\exp\left(-\frac{1}{2\sigma^{2}}\left(n-1\right)s^{2}\right)\underbrace{\exp\left(-\frac{1}{2\sigma^{2}}n\left(\overline{x}-\mu\right)^{2}\right)\left(\frac{\sigma}{n}\right)^{-1/2}}_{\text{kernel de una normal}}\left(\frac{\sigma}{n}\right)^{1/2}\\
\text{integrando}\\
\implies p\left(\sigma^{2}|\mathbf{x}\right) & \propto\left(\sigma^{2}\right)^{-\left(n/2+1\right)}\exp\left(-\frac{1}{2\sigma^{2}}\left(n-1\right)s^{2}\right)\\
\sigma^{2}|\mathbf{x} & \sim\chi^{2}-\mathbf{inv}\left(n,s^{2}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Paragraph
4.5.1c.
\end_layout

\begin_layout Standard
calcular la distribución a posteriori marginal de 
\begin_inset Formula $\mu$
\end_inset


\begin_inset Formula 
\begin{align*}
p\left(\mu|\mathbf{x}\right) & =\int_{0}^{\infty}p\left(\mu,\sigma^{2}|\mathbf{x}\right)d\sigma^{2}\\
 & \propto\int_{0}^{\infty}\left(\sigma^{2}\right)^{-3/2}\sigma^{-n/2}\exp\left(-\frac{1}{2\sigma^{2}}A\right)d\sigma^{2}\\
A & =\sum\left(x_{i}-\overline{x}\right)^{2}+n\left(\overline{x}-\mu\right)^{2}
\end{align*}

\end_inset

con el siguiente cambio de variable 
\begin_inset Formula $z=A/\left(2\sigma^{2}\right)$
\end_inset

, 
\begin_inset Formula $\text{\ensuremath{\sigma^{2}=A/2z} }$
\end_inset

 y 
\begin_inset Formula $d\sigma^{2}=-\frac{A}{2z^{2}}dz$
\end_inset

.
 Luego 
\begin_inset Formula 
\begin{align*}
p\left(\mu|\mathbf{x}\right) & \propto\int_{0}^{\infty}\left(\frac{A}{2z}\right)^{-3/2-n/2}\exp\left(-z\right)\left(-\frac{A}{2z^{2}}\right)dz\\
 & \propto\left(\frac{A}{2z}\right)^{-1/2-n/2}
\end{align*}

\end_inset


\end_layout

\begin_layout Paragraph
4.5.1d.
\end_layout

\begin_layout Standard
Utilice los resultados anteriores para encontrar la distribución predictiva
 a posteriori usando el método de la composición.
 
\end_layout

\begin_layout Enumerate
para 
\begin_inset Formula $s=1\ldots,S$
\end_inset


\end_layout

\begin_layout Enumerate
genera 
\begin_inset Formula $\mu^{\left(s\right)}\sim p\left(\mu|\mathbf{y}\right)$
\end_inset


\end_layout

\begin_layout Enumerate
genera 
\begin_inset Formula $\sigma^{2\left(s\right)}\sim p\left(\sigma^{2}|\mathbf{y}\right)$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $y^{s}\sim p\left(x|\mu^{\left(s\right)},\sigma^{2\left(s\right)}\right)$
\end_inset


\end_layout

\begin_layout Paragraph
4.5.1e
\end_layout

\begin_layout Standard
Repita a) y c) con la priori informativa: 
\begin_inset Formula $p\left(\mu,\sigma^{2}\right)=p\left(\mu|\sigma^{2}\right)p\left(\sigma^{2}\right)$
\end_inset

.
 Luego 
\begin_inset Formula 
\begin{align*}
p\left(\mu,\sigma^{2}|\mathbf{x}\right) & \propto p\left(\mu,\sigma^{2}\right)p\left(\mathbf{x}|\mu,\sigma^{2}\right)\\
 & =p\left(\mu|\sigma^{2}\right)p\left(\sigma^{2}\right)p\left(\mathbf{x}|\mu,\sigma^{2}\right)\\
 & =
\end{align*}

\end_inset


\end_layout

\begin_layout Paragraph
4.5.2a.
\end_layout

\begin_layout Standard
Encontre la distribución a posterior de 
\begin_inset Formula $\beta,\sigma^{2}$
\end_inset

.
 Conocido que la distribución a priori de 
\begin_inset Formula $p\left(\beta,\sigma^{2}\right)\propto\sigma^{-2}$
\end_inset


\begin_inset Formula 
\begin{align*}
y|\beta,\sigma^{2},X & \sim N\left(X\beta,\sigma^{2}I\right)\\
p\left(y|\beta,\sigma^{2},X\right) & \propto\det\left(\sigma^{2}I\right)^{-1/2}\exp\left(-\frac{1}{2\sigma^{2}}\left(y-X\beta\right)^{t}\left(y-X\beta\right)\right)\\
 & =\left(\sigma^{2}\right)^{-1/2}\exp\left(-\frac{1}{2\sigma^{2}}\left(y-X\beta\right)^{t}\left(y-X\beta\right)\right)\\
 & =\\
\implies p\left(\beta,\sigma^{2}|y,X\right) & \propto\left(\sigma^{2}\right)^{-n/2}\exp\left(-\frac{1}{2\sigma^{2}}\left(y-X\beta\right)^{t}\left(y-X\beta\right)\right)\sigma^{-2}\\
 & =\left(\sigma^{2}\right)^{-n/2-2}\exp\left(-\frac{1}{2\sigma^{2}}\left(y-X\beta\right)^{t}\left(y-X\beta\right)\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Paragraph*
4.5.2b.
\end_layout

\begin_layout Standard
Demuestre que la distribución a posterior de 
\series bold

\begin_inset Formula $\beta$
\end_inset

 
\series default
dado 
\begin_inset Formula $\sigma^{2}$
\end_inset

 corresponde a una distribución normal
\series bold
 
\begin_inset Formula $\hat{\beta},\sigma^{2}\left(X^{t}X\right)^{-1}$
\end_inset

.
 
\series default
Sol: Sabemos que 
\begin_inset Formula 
\begin{align*}
p\left(\beta,\sigma^{2}|y\right) & =p\left(\sigma^{2}|\beta,y\right)p\left(\beta|y\right) & \implies & p\left(\beta|y\right)=\frac{p\left(\beta,\sigma^{2}|y\right)}{p\left(\sigma^{2}|\beta,y\right)}=\frac{p\left(y|\beta,\sigma^{2}\right)p\left(\beta,\sigma^{2}\right)}{p\left(\sigma^{2}|\beta,y\right)}\\
p\left(\beta,\sigma^{2}|y\right) & =p\left(\beta|\sigma^{2},y\right)p\left(\sigma^{2}|y\right) & \implies & p\left(\sigma^{2}|y\right)=\frac{p\left(y|\beta,\sigma^{2}\right)p\left(\beta,\sigma^{2}\right)}{p\left(\beta|\sigma^{2},y\right)}
\end{align*}

\end_inset

El camino quizás es más simple si hacemos la siguiente operatoria:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
p\left(\beta|\sigma^{2},y\right) & =\frac{p\left(\beta,\sigma^{2}|,y\right)}{p\left(\sigma^{2}|y\right)}\\
 & \propto p\left(\beta,\sigma^{2}|,y\right)\\
 & =\left(\sigma^{2}\right)^{-n/2-2}\exp\left(-\frac{1}{2\sigma^{2}}\left(y-X\beta\right)^{t}\left(y-X\beta\right)\right)\\
 & \propto\exp\left(-\frac{1}{2\sigma^{2}}\left(y-X\beta\right)^{t}\left(y-X\beta\right)\right)\\
 & =\exp\left(-\frac{1}{2\sigma^{2}}\left(y-X\hat{\beta}\right)^{t}\left(y-X\hat{\beta}\right)-\frac{1}{2\sigma^{2}}\left(\beta-\hat{\beta}\right)^{t}X^{t}X\left(\beta-\hat{\beta}\right)\right)\\
 & \propto\exp\left(-\frac{1}{2\sigma^{2}}\left(\beta-\hat{\beta}\right)^{t}X^{t}X\left(\beta-\hat{\beta}\right)\right)\\
\implies\beta|\sigma^{2},y & \sim N\left(\hat{\beta},\sigma^{2}\left(X^{t}X\right)^{-1}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Paragraph
4.5.2c.
\end_layout

\begin_layout Standard
Encuentre la distribución a posterior de 
\begin_inset Formula $\sigma^{2}$
\end_inset

 , (ver ejercicio 14.4 BDA)
\begin_inset Formula 
\begin{align*}
p\left(\sigma^{2}|y\right) & =\frac{p\left(\beta,\sigma^{2}|,y\right)}{p\left(\beta|\sigma^{2},y\right)}\\
 & \propto\frac{\left(\sigma^{2}\right)^{-n/2-2}\exp\left(-\frac{1}{2\sigma^{2}}\left(y-X\beta\right)^{t}\left(y-X\beta\right)\right)}{\det\left(\sigma^{2}\left(X^{t}X\right)^{-1}\right)^{-1/2}\exp\left(-\frac{1}{2\sigma^{2}}\left(\beta-\hat{\beta}\right)^{t}X^{t}X\left(\beta-\hat{\beta}\right)\right)}\\
 & =\frac{\left(\sigma^{2}\right)^{-n/2-2}\exp\left(-\frac{1}{2\sigma^{2}}\left(y-X\hat{\beta}\right)^{t}\left(y-X\hat{\beta}\right)-\frac{1}{2\sigma^{2}}\left(\beta-\hat{\beta}\right)^{t}X^{t}X\left(\beta-\hat{\beta}\right)\right)}{\det\left(\sigma^{2}\left(X^{t}X\right)^{-1}\right)^{-1/2}\exp\left(-\frac{1}{2\sigma^{2}}\left(\beta-\hat{\beta}\right)^{t}X^{t}X\left(\beta-\hat{\beta}\right)\right)}\\
 & =\frac{\left(\sigma^{2}\right)^{-n/2-2}\exp\left(-\frac{1}{2\sigma^{2}}\left(y-X\hat{\beta}\right)^{t}\left(y-X\hat{\beta}\right)\right)}{\det\left(\sigma^{2}\left(X^{t}X\right)^{-1}\right)^{-1/2}\exp\left(0\right)}\\
 & =\frac{\left(\sigma^{2}\right)^{-n/2-2}\exp\left(-\frac{1}{2\sigma^{2}}\left(y-X\hat{\beta}\right)^{t}\left(y-X\hat{\beta}\right)\right)}{\left(\sigma^{2k}\right)^{-1/2}\det\left(\left(X^{t}X\right)^{-1}\right)^{-1/2}\exp\left(0\right)}\\
 & \propto\left(\sigma^{2}\right)^{-n/2-2+k/2}\exp\left(-\frac{1}{2\sigma^{2}}\left(y-X\hat{\beta}\right)^{t}\left(y-X\hat{\beta}\right)\right)\\
\implies\sigma^{2}|y & \sim Inv-\chi^{2}\left(n-k,s^{2}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Paragraph
4.5.2d 
\end_layout

\begin_layout Standard
Si 
\begin_inset Formula $\widetilde{y}$
\end_inset

 es una nueva respuesta, existen 
\begin_inset Formula $a$
\end_inset

 y 
\begin_inset Formula $b$
\end_inset

 tales que 
\end_layout

\begin_layout Section
Ejemplos de cátedra
\end_layout

\begin_layout Standard
demuestre que que modelo probit con 
\begin_inset Formula $\pi\left(x\right)=\Phi\left(\beta_{0}+\beta_{1}x|\mu,\sigma^{2}\right)$
\end_inset

 es no identificado para 
\begin_inset Formula $\mu$
\end_inset

 y 
\begin_inset Formula $\sigma^{2}$
\end_inset

.
 La demostración se basa en que 
\begin_inset Formula 
\begin{align*}
Y_{i}|x_{i} & \sim\text{ber}\left(\pi\left(x_{i}\right)\right)\\
\implies\pi\left(x\right) & =\Phi\left(\beta_{0}+\beta_{1}x|\mu,\sigma^{2}\right)\\
\pi\left(x\right) & =\Phi_{0,1}\left(\frac{\beta_{0}+\beta_{1}x-\mu}{\sigma}\right)\\
\pi\left(x\right) & =\Phi_{0,1}\left(\beta_{0}^{*}+\beta_{1}^{*}x\right)
\end{align*}

\end_inset

entonces existen parámetros observacionalmente equivalentes.
\end_layout

\begin_layout Paragraph
Intervalo de Confianza 
\end_layout

\begin_layout Standard
El parámetro está cubierto por el intervalo de confianza con una probabilidad
 
\begin_inset Formula $1-\alpha$
\end_inset

.
\end_layout

\begin_layout Paragraph*
Identificabilidad bayesiana
\end_layout

\begin_layout Standard
Si tengo un modelo clasicamente no identificado, en bayesiana podemos
\end_layout

\end_body
\end_document
